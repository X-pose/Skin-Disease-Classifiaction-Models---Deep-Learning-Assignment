{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNnNwgz7QVybf3KqRFXwtRi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/X-pose/Skin-Disease-Classifiaction-Models---Deep-Learning-Assignment/blob/IT21226632---Weerasinghe-W.W.A.B.M/DenseNet121_Skin_Disease_classification_model_IT21226632.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Necessary Libraries\n",
        "\n",
        "The code begins by importing the required libraries: zipfile for handling zip files and os for interacting with the operating system. The drive module from google.colab is also imported to allow access to Google Drive.\n",
        "Set CUDA Configuration:\n",
        "\n",
        "The environment variable PYTORCH_CUDA_ALLOC_CONF is configured to expandable_segments:True.\n",
        "This setting is intended to optimize CUDA memory allocation for PyTorch, helping to prevent memory-related issues when running deep learning models.\n",
        "Mount Google Drive:\n",
        "\n",
        "The code mounts Google Drive to the Colab environment by calling drive.mount('/content/drive').\n",
        "This step enables access to files stored in the user's Google Drive, allowing the code to read the dataset zip file directly.\n",
        "Specify the Dataset Zip File Path:\n",
        "\n",
        "A variable, zip_file_path, is defined to specify the path to the dataset zip file in Google Drive. This path directs the code to the specific file that contains the dataset for skin disease classification.\n",
        "Define Extraction Directory:\n",
        "\n",
        "Another variable, extract_dir, is created to specify the directory where the contents of the zip file will be extracted. This directory is set to '/content/Extracted_data'.\n",
        "Create Extraction Directory:\n",
        "\n",
        "The os.makedirs function is called with exist_ok=True, ensuring that the extraction directory is created if it does not already exist. This prevents errors if the directory is attempted to be created multiple times.\n",
        "Extract the Zip File:\n",
        "\n",
        "The code uses a with statement to open the zip file in read mode. Inside this block, the extractall method of the ZipFile object is invoked to extract all the contents of the zip file into the specified extraction directory.\n",
        "Confirmation Message:\n",
        "\n",
        "Finally, a print statement confirms that the dataset has been successfully extracted to the designated directory, informing the user of the completion of the extraction process.\n"
      ],
      "metadata": {
        "id": "Q62QN1XSTydD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SdZVSkoyRFy",
        "outputId": "510226d1-9bb6-4a68-e92a-55954f2cadb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset extracted to /content/Extracted_data\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "from google.colab import drive\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to dataset zip file in Google Drive\n",
        "zip_file_path = '/content/drive/My Drive/Skin Disease.v1i.multiclass.zip'\n",
        "\n",
        "# Directory to extract the files\n",
        "extract_dir = '/content/Extracted_data'\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(f\"Dataset extracted to {extract_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install torch torchvision numpy pandas matplotlib scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZOyYvb-yXev",
        "outputId": "b77edd7e-9336-46ec-89fc-2484698c3c1e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms, datasets, models\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch import nn, optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "ENQ2enQgycQy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SkinDiseaseDataset Class\n",
        "The SkinDiseaseDataset class extends the Dataset class from PyTorch to manage a dataset of skin disease images and their corresponding labels.\n",
        "\n",
        "**Initialization (__init__ method):**\n",
        "\n",
        "The class is initialized with a CSV file containing annotations, a root directory for images, and optional transformations for image preprocessing. The CSV file is read into a DataFrame for easy access to image paths and labels.\n",
        "Length (__len__ method):\n",
        "\n",
        "Returns the total number of samples in the dataset based on the number of entries in the annotations.\n",
        "Get Item (__getitem__ method):\n",
        "\n",
        "Loads an image from the specified path using its index. If an error occurs while loading the image, it prints an error message and returns None. The corresponding label is retrieved as a tensor. If transformations are provided, they are applied to the image before returning it alongside the label."
      ],
      "metadata": {
        "id": "B8xpj0BsUTq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SkinDiseaseDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.annotations = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.annotations.iloc[idx, 0])\n",
        "        try:\n",
        "            image = Image.open(img_name).convert('RGB')\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_name}: {e}\")\n",
        "            return None, None  # Handle the error as needed\n",
        "\n",
        "        label = torch.tensor(self.annotations.iloc[idx, 1:].values.astype('float32'))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "6SE0_vXpyhEY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Preparation and Data Loading\n",
        "**Image Transformations:**\n",
        "\n",
        "Training Transformations (train_transform):\n",
        "\n",
        "Resizes images to\n",
        "224\n",
        "×\n",
        "224\n",
        "224×224 pixels.\n",
        "Applies random horizontal flips and rotations to augment the dataset.\n",
        "Adjusts brightness, contrast, saturation, and hue.\n",
        "Applies random affine transformations for slight translations and scaling.\n",
        "Converts images to tensors and normalizes them using ImageNet statistics.\n",
        "\n",
        "**Validation Transformations (val_transform):**\n",
        "\n",
        "Resizes images to\n",
        "224\n",
        "×\n",
        "224\n",
        "224×224 pixels.\n",
        "Converts images to tensors and normalizes them similarly to training data.\n",
        "\n",
        "**Dataset Paths:**\n",
        "\n",
        "Specifies paths to CSV files containing labels and directories for training and testing images.\n",
        "\n",
        "**Loading Datasets:**\n",
        "\n",
        "Initializes SkinDiseaseDataset objects for both training and testing datasets, using the defined transformations.\n",
        "\n",
        "**Splitting the Dataset:**\n",
        "\n",
        "Utilizes train_test_split to divide the training dataset into training and validation sets, with 20% reserved for validation.\n",
        "\n",
        "**Creating Data Loaders:**\n",
        "\n",
        "Defines DataLoader instances for the training, validation, and test datasets with a batch size of 32.\n",
        "Enables shuffling for the training data to enhance model training."
      ],
      "metadata": {
        "id": "JBL6NVFMUx73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define image transformations with data augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images to 224x224 for DenseNet\n",
        "    transforms.RandomHorizontalFlip(),  # Randomly flip images\n",
        "    transforms.RandomRotation(10),  # Randomly rotate images\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),  # Change brightness, contrast, saturation\n",
        "    transforms.RandomAffine(0, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
        "    transforms.ToTensor(),           # Convert image to tensor\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images for validation\n",
        "    transforms.ToTensor(),           # Convert image to tensor\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize\n",
        "])\n",
        "\n",
        "# Path to CSV and image folder\n",
        "train_csv_path = '/content/Extracted_data/train/_classes.csv'\n",
        "test_csv_path = '/content/Extracted_data/test/_classes.csv'\n",
        "train_img_dir = '/content/Extracted_data/train'\n",
        "test_img_dir = '/content/Extracted_data/test'\n",
        "\n",
        "# Load the datasets\n",
        "train_dataset = SkinDiseaseDataset(csv_file=train_csv_path, root_dir=train_img_dir, transform=train_transform)\n",
        "test_dataset = SkinDiseaseDataset(csv_file=test_csv_path, root_dir=test_img_dir, transform=val_transform)\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_set, val_set = train_test_split(train_dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "ldjVK55xynWT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modified DenseNet Model for Transfer Learning\n",
        "**Imports**\n",
        "\n",
        "The code imports necessary libraries, including PyTorch and the pre-trained DenseNet model from torchvision.\n",
        "\n",
        "# Class Definition:\n",
        "\n",
        "ModifiedDenseNet: Inherits from nn.Module and modifies the pre-trained DenseNet for specific classification tasks.\n",
        "\n",
        "**Constructor (__init__):**\n",
        "\n",
        "Initializes the base DenseNet model and keeps only the feature extraction layers.\n",
        "Adds a convolutional reduction layer to adjust feature dimensions.\n",
        "Implements a global average pooling layer.\n",
        "Defines a custom classifier with multiple fully connected layers, batch normalization, ReLU activations, and dropout for regularization.\n",
        "Calls a private method to freeze the specified number of layers to prevent their weights from being updated during training.\n",
        "\n",
        "**Layer Freezing:**\n",
        "\n",
        "_freeze_layers: This method freezes the weights of the initial layers based on the specified freeze_layers count, allowing fine-tuning of only the later layers.\n",
        "\n",
        "**Forward Method:**\n",
        "\n",
        "Defines how input data flows through the model:\n",
        "Extracts features using the DenseNet backbone.\n",
        "Applies the reduction layer.\n",
        "Pools the features and flattens them for classification.\n",
        "\n",
        "**Setup Function:**\n",
        "\n",
        "setup_densenet_transfer_learning: This function creates an instance of the modified DenseNet model and performs the following:\n",
        "Computes the total and trainable parameters in the model.\n",
        "Moves the model to a GPU if available.\n",
        "\n",
        "**Example Usage:**\n",
        "\n",
        "The example at the bottom demonstrates how to create the model and obtain the computing device (CPU/GPU)."
      ],
      "metadata": {
        "id": "TldnlJVoV9Om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class ModifiedDenseNet(nn.Module):\n",
        "    def __init__(self, num_classes=17, freeze_layers=30, reduction_factor=2):\n",
        "        super(ModifiedDenseNet, self).__init__()\n",
        "\n",
        "        # Load the pre-trained DenseNet model\n",
        "        base_model = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
        "\n",
        "        # Keep the features portion of the model\n",
        "        self.features = base_model.features\n",
        "\n",
        "        # Add a reduction layer\n",
        "        self.reduction = nn.Sequential(\n",
        "            nn.Conv2d(1024, 1664, kernel_size=3, stride=reduction_factor, padding=1),\n",
        "            nn.BatchNorm2d(1664),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Global pooling\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # Modified classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(1664, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.6),\n",
        "            nn.Linear(1024, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "        # Freeze layers\n",
        "        self._freeze_layers(freeze_layers)\n",
        "\n",
        "    def _freeze_layers(self, freeze_layers):\n",
        "        layers_frozen = 0\n",
        "        for name, param in self.features.named_parameters():\n",
        "            if layers_frozen < freeze_layers:\n",
        "                param.requires_grad = False\n",
        "                layers_frozen += 1\n",
        "            else:\n",
        "                break\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        reduced = self.reduction(features) # Pass the output of features to reduction\n",
        "        out = self.avgpool(reduced)\n",
        "        out = torch.flatten(out, 1)\n",
        "        return self.classifier(out)\n",
        "\n",
        "def setup_densenet_transfer_learning(num_classes=17, freeze_layers=30, reduction_factor=2):\n",
        "    # Create the modified model\n",
        "    model = ModifiedDenseNet(num_classes=num_classes,\n",
        "                            freeze_layers=freeze_layers,\n",
        "                            reduction_factor=reduction_factor)\n",
        "\n",
        "    # Print model statistics\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    print(f\"Total parameters: {total_params}\")\n",
        "    print(f\"Trainable parameters: {trainable_params}\")\n",
        "\n",
        "    # Move the model to GPU if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    return model, device\n",
        "\n",
        "# Example usage\n",
        "model, device = setup_densenet_transfer_learning(num_classes=17, freeze_layers=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPd0VmMbytJD",
        "outputId": "b8f0e0a5-fcae-493e-e023-7964e015cc85"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters: 24268561\n",
            "Trainable parameters: 24027345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class Weights and Optimizer Setup for Training\n",
        "\n",
        "**Class Counts:**\n",
        "\n",
        "class_counts: Computes the sum of instances for each class from the training dataset annotations. This is done by summing the values in all columns (excluding the first column, which contains image file names).\n",
        "Class Weights:\n",
        "\n",
        "smoothing_factor: A small value added to class counts to prevent division by zero and to smooth the weights. It can be adjusted based on your needs.\n",
        "class_weights: Calculates the inverse of the class counts (adjusted by the smoothing factor) to give more importance to under-represented classes during training. This helps mitigate class imbalance issues.\n",
        "The weights are then normalized by dividing by their sum to ensure they sum to 1.\n",
        "\n",
        "**Loss Function:**\n",
        "\n",
        "criterion: Defines the loss function using BCEWithLogitsLoss, which combines a sigmoid layer and binary cross-entropy loss in a single class. The pos_weight parameter is set to the calculated class weights to balance the loss for each class based on their frequency.\n",
        "\n",
        "**Optimizer Setup:**\n",
        "\n",
        "optimizer: Utilizes the AdamW optimizer for training, which is an improved version of the Adam optimizer that includes weight decay for better generalization. The learning rate and weight decay can be adjusted according to the specific needs of the training process.\n",
        "\n",
        "**Learning Rate Scheduler:**\n",
        "\n",
        "scheduler: Uses the ReduceLROnPlateau scheduler, which reduces the learning rate when a metric has stopped improving (in this case, the loss). The factor indicates how much to reduce the learning rate, and patience specifies how many epochs to wait before reducing the learning rate if no improvement is observed."
      ],
      "metadata": {
        "id": "CeWiBnGlYTt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = np.sum(train_dataset.annotations.iloc[:, 1:].values, axis=0)\n",
        "smoothing_factor = 1.0  # Adjust this value based on your needs\n",
        "class_weights = 1.0 / torch.tensor(class_counts + smoothing_factor, dtype=torch.float)\n",
        "class_weights = class_weights / torch.sum(class_weights)\n",
        "\n",
        "# Define the loss function with weights\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights.to(device))\n",
        "\n",
        "# Set Up the Optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.0001)  # Consider adjusting lr and weight_decay\n",
        "\n",
        "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
        " # Consider adjusting parameters"
      ],
      "metadata": {
        "id": "ZNsBupjSy0_D"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "w0JcbBlky5M9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "wewoiKutblo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def calculate_f1(preds, targets, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calculates F1 score for multi-label classification.\n",
        "\n",
        "    Args:\n",
        "        preds (torch.Tensor): Model predictions (probabilities).\n",
        "        targets (torch.Tensor): Ground truth labels (binary, multi-label).\n",
        "        threshold (float): Threshold to convert probabilities to binary predictions.\n",
        "\n",
        "    Returns:\n",
        "        float: F1 score.\n",
        "    \"\"\"\n",
        "    preds = (preds > threshold).float().clone()  # Avoid in-place operations\n",
        "    tp = (preds * targets).sum().to(torch.float32)\n",
        "    fp = (preds * (1 - targets)).sum().to(torch.float32)\n",
        "    fn = ((1 - preds) * targets).sum().to(torch.float32)\n",
        "\n",
        "    precision = tp / (tp + fp + 1e-8)\n",
        "    recall = tp / (tp + fn + 1e-8)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "\n",
        "    return f1.item()\n",
        "\n",
        "def find_best_threshold(model, val_loader, device):\n",
        "    \"\"\"\n",
        "    Finds the best threshold for binary classification based on the F1 score.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The trained model.\n",
        "        val_loader (DataLoader): Validation data loader.\n",
        "        device (torch.device): Device (CPU/GPU).\n",
        "\n",
        "    Returns:\n",
        "        tuple: best threshold and its corresponding F1 score.\n",
        "    \"\"\"\n",
        "    thresholds = np.arange(0.1, 1.0, 0.1)\n",
        "    best_f1 = 0\n",
        "    best_threshold = 0.5\n",
        "\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            preds = torch.sigmoid(outputs)\n",
        "            all_preds.append(preds.cpu())\n",
        "            all_targets.append(targets.cpu())\n",
        "\n",
        "    all_preds = torch.cat(all_preds)\n",
        "    all_targets = torch.cat(all_targets)\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        f1 = calculate_f1(all_preds, all_targets, threshold=threshold)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = threshold\n",
        "\n",
        "    return best_threshold, best_f1\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
        "    \"\"\"\n",
        "    Plots the confusion matrix.\n",
        "\n",
        "    Args:\n",
        "        y_true (torch.Tensor): True labels.\n",
        "        y_pred (torch.Tensor): Predicted labels.\n",
        "        class_names (list): List of class names.\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true.cpu(), y_pred.cpu())\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "def train_model(model: torch.nn.Module, criterion: torch.nn.Module, optimizer: torch.optim.Optimizer,\n",
        "                scheduler: torch.optim.lr_scheduler._LRScheduler, train_loader, val_loader, num_epochs: int = 25,\n",
        "                class_names: list = None) -> torch.nn.Module:\n",
        "    \"\"\"\n",
        "    Trains the model and evaluates it on the validation set.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model to train.\n",
        "        criterion (torch.nn.Module): The loss function.\n",
        "        optimizer (torch.optim.Optimizer): The optimizer.\n",
        "        scheduler (torch.optim.lr_scheduler._LRScheduler): Learning rate scheduler.\n",
        "        train_loader: Training data loader.\n",
        "        val_loader: Validation data loader.\n",
        "        num_epochs (int): Number of epochs to train.\n",
        "        class_names (list): List of class names.\n",
        "\n",
        "    Returns:\n",
        "        torch.nn.Module: The trained model.\n",
        "    \"\"\"\n",
        "    best_model_weights = model.state_dict()\n",
        "    best_f1 = 0.0\n",
        "    best_threshold = 0.9\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_f1s = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "                data_loader = train_loader\n",
        "            else:\n",
        "                model.eval()\n",
        "                data_loader = val_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_outputs = []\n",
        "            running_labels = []\n",
        "\n",
        "            for inputs, labels in data_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_outputs.append(outputs)\n",
        "                running_labels.append(labels)\n",
        "\n",
        "            epoch_loss = running_loss / len(data_loader.dataset)\n",
        "\n",
        "            if phase == 'train':\n",
        "                train_losses.append(epoch_loss)\n",
        "            else:\n",
        "                val_losses.append(epoch_loss)\n",
        "\n",
        "            epoch_outputs = torch.cat(running_outputs)\n",
        "            epoch_labels = torch.cat(running_labels)\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.5f}')\n",
        "\n",
        "            if phase == 'val':\n",
        "                with torch.no_grad():\n",
        "                    best_threshold, best_f1 = find_best_threshold(model, val_loader, device)\n",
        "                    val_f1s.append(best_f1)\n",
        "\n",
        "                print(f'Validation F1 (best threshold={best_threshold}): {best_f1:.5f}')\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step(epoch_loss)\n",
        "\n",
        "        # Checkpoint for best model based on F1\n",
        "        if best_f1 > max(val_f1s, default=0):\n",
        "            best_model_weights = model.state_dict()\n",
        "            torch.save(best_model_weights, 'best_model.pth')\n",
        "\n",
        "    print(f'Best validation F1: {max(val_f1s, default=0):.5f}')\n",
        "\n",
        "    model.load_state_dict(best_model_weights)\n",
        "\n",
        "    # Plotting Loss\n",
        "    plt.figure(figsize=(20, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.title('Loss over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(val_f1s, label='Validation F1', color='blue')\n",
        "    plt.title('Validation F1 over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('F1 Score')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage of the train_model function\n",
        "# Assuming criterion, optimizer, scheduler, train_loader, val_loader, and model are defined elsewhere\n",
        "class_names = ['Actinic', 'Atopic', 'Benign', 'Candidiasis', 'Dermatitis', 'Dermatofibroma',\n",
        "               'Melanocytic', 'Melanoma', 'Ringworm', 'Squamous', 'Tinea', 'Vascular',\n",
        "               'Carcinoma', 'Cell', 'Keratosis', 'Lesion', 'Nevus']\n",
        "\n",
        "trained_model = train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs=15, class_names=class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "314Pkauyy_PM",
        "outputId": "612c382f-944b-4876-9826-985de1ad99e6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "----------\n",
            "train Loss: 0.44951\n",
            "val Loss: 0.35864\n",
            "Validation F1 (best threshold=0.5): 0.59741\n",
            "Epoch 2/15\n",
            "----------\n",
            "train Loss: 0.22815\n",
            "val Loss: 0.23769\n",
            "Validation F1 (best threshold=0.4): 0.68846\n",
            "Epoch 3/15\n",
            "----------\n",
            "train Loss: 0.13730\n",
            "val Loss: 0.16065\n",
            "Validation F1 (best threshold=0.30000000000000004): 0.68916\n",
            "Epoch 4/15\n",
            "----------\n",
            "train Loss: 0.09251\n",
            "val Loss: 0.11394\n",
            "Validation F1 (best threshold=0.2): 0.70855\n",
            "Epoch 5/15\n",
            "----------\n",
            "train Loss: 0.07036\n",
            "val Loss: 0.09874\n",
            "Validation F1 (best threshold=0.2): 0.68053\n",
            "Epoch 6/15\n",
            "----------\n",
            "train Loss: 0.05564\n",
            "val Loss: 0.07308\n",
            "Validation F1 (best threshold=0.2): 0.65169\n",
            "Epoch 7/15\n",
            "----------\n",
            "train Loss: 0.04711\n",
            "val Loss: 0.06169\n",
            "Validation F1 (best threshold=0.1): 0.67743\n",
            "Epoch 8/15\n",
            "----------\n",
            "train Loss: 0.04068\n",
            "val Loss: 0.05182\n",
            "Validation F1 (best threshold=0.1): 0.73959\n",
            "Epoch 9/15\n",
            "----------\n",
            "train Loss: 0.03601\n",
            "val Loss: 0.04219\n",
            "Validation F1 (best threshold=0.1): 0.76086\n",
            "Epoch 10/15\n",
            "----------\n",
            "train Loss: 0.03250\n",
            "val Loss: 0.03917\n",
            "Validation F1 (best threshold=0.1): 0.75877\n",
            "Epoch 11/15\n",
            "----------\n",
            "train Loss: 0.03005\n",
            "val Loss: 0.03341\n",
            "Validation F1 (best threshold=0.1): 0.77462\n",
            "Epoch 12/15\n",
            "----------\n",
            "train Loss: 0.02768\n",
            "val Loss: 0.03171\n",
            "Validation F1 (best threshold=0.1): 0.78912\n",
            "Epoch 13/15\n",
            "----------\n",
            "train Loss: 0.02574\n",
            "val Loss: 0.02794\n",
            "Validation F1 (best threshold=0.1): 0.79361\n",
            "Epoch 14/15\n",
            "----------\n",
            "train Loss: 0.02396\n",
            "val Loss: 0.02489\n",
            "Validation F1 (best threshold=0.1): 0.81213\n",
            "Epoch 15/15\n",
            "----------\n",
            "train Loss: 0.02444\n",
            "val Loss: 0.02545\n",
            "Validation F1 (best threshold=0.1): 0.79436\n",
            "Best validation F1: 0.81213\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the Model"
      ],
      "metadata": {
        "id": "-DHSfhCPbrff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'final_trained_model.pth')\n"
      ],
      "metadata": {
        "id": "8MMy2ww13YAQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Model"
      ],
      "metadata": {
        "id": "JFwamuEzbtzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have defined the model architecture again\n",
        "model.load_state_dict(torch.load('final_trained_model.pth'))  # Load the saved model\n",
        "model.eval()  # Set the model to evaluation mode\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMf6_0pI3bFd",
        "outputId": "eb373c17-57e8-49b2-851e-b7376ada1916"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-04b557415d30>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('final_trained_model.pth'))  # Load the saved model\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModifiedDenseNet(\n",
              "  (features): Sequential(\n",
              "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu0): ReLU(inplace=True)\n",
              "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (denseblock1): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition1): _Transition(\n",
              "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock2): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition2): _Transition(\n",
              "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock3): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer17): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer18): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer19): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer20): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer21): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer22): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer23): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer24): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition3): _Transition(\n",
              "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock4): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (reduction): Sequential(\n",
              "    (0): Conv2d(1024, 1664, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=1664, out_features=1024, bias=True)\n",
              "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.6, inplace=False)\n",
              "    (4): Linear(in_features=1024, out_features=256, bias=True)\n",
              "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU()\n",
              "    (7): Dropout(p=0.4, inplace=False)\n",
              "    (8): Linear(in_features=256, out_features=17, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
        "    \"\"\"\n",
        "    Plots the confusion matrix for multi-label classification.\n",
        "\n",
        "    Args:\n",
        "        y_true (torch.Tensor): True labels.\n",
        "        y_pred (torch.Tensor): Predicted labels.\n",
        "        class_names (list): List of class names.\n",
        "    \"\"\"\n",
        "    # Calculate confusion matrix for each label\n",
        "    cm = multilabel_confusion_matrix(y_true.cpu(), y_pred.cpu())\n",
        "\n",
        "    # Plot individual confusion matrices\n",
        "    fig, axes = plt.subplots(4, 5, figsize=(20, 15))\n",
        "    axes = axes.ravel()\n",
        "    for i, (label, matrix) in enumerate(zip(class_names, cm)):\n",
        "        sns.heatmap(matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, ax=axes[i])\n",
        "        axes[i].set_title(label)\n",
        "        axes[i].set_xlabel(\"Predicted\")\n",
        "        axes[i].set_ylabel(\"True\")\n",
        "\n",
        "    # Remove any unused subplots\n",
        "    for i in range(len(class_names), len(axes)):\n",
        "        fig.delaxes(axes[i])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SULQJyE5-_KQ",
        "outputId": "fd5470a3-8003-4c4a-9e51-a6e1a10759e1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "CcqxtAgnb3Oe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from tabulate import tabulate\n",
        "\n",
        "def evaluate_model(model, test_loader, device, class_names, threshold=0.1):\n",
        "    \"\"\"\n",
        "    Evaluate the model on a given data loader and calculate accuracy and F1 scores for each class.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The trained model.\n",
        "        test_loader (torch.utils.data.DataLoader): Data loader for the evaluation dataset.\n",
        "        device (torch.device): The device to run the model on (CPU or GPU).\n",
        "        class_names (list): List of class names.\n",
        "        threshold (float): Threshold to convert probabilities to binary predictions.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing accuracy, precision, recall, and F1 scores for each class.\n",
        "        float: The average F1 score across all classes.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Get the model predictions\n",
        "            outputs = model(images)\n",
        "            preds = torch.sigmoid(outputs)  # Apply sigmoid to get probabilities\n",
        "\n",
        "            # Convert probabilities to binary predictions\n",
        "            preds_binary = (preds > threshold).float()\n",
        "\n",
        "            all_preds.append(preds_binary.cpu())\n",
        "            all_targets.append(labels.cpu())\n",
        "\n",
        "    # Concatenate all predictions and targets\n",
        "    all_preds = torch.cat(all_preds)\n",
        "    all_targets = torch.cat(all_targets)\n",
        "\n",
        "    # Debugging prints\n",
        "    print(f\"all_targets.shape: {all_targets.shape}\")  # Shape should be [num_samples, num_classes]\n",
        "    print(f\"class_names length: {len(class_names)}\")  # Should match the number of classes (all_targets.shape[1])\n",
        "\n",
        "    # Ensure class_names length matches the number of classes\n",
        "    if all_targets.size(1) != len(class_names):\n",
        "        raise ValueError(f\"Mismatch between the number of classes ({all_targets.size(1)}) and the length of class_names ({len(class_names)}).\")\n",
        "\n",
        "    # Calculate overall accuracy\n",
        "    correct_predictions = (all_preds == all_targets).float()\n",
        "    accuracy = correct_predictions.sum() / correct_predictions.numel()\n",
        "\n",
        "    # Initialize a dictionary to store F1 scores and an average F1 tracker\n",
        "    f1_scores = {}\n",
        "    f1_sum = 0\n",
        "    num_classes = all_targets.size(1)  # Assuming targets shape is [num_samples, num_classes]\n",
        "\n",
        "    # Create a table list to store class-wise metrics\n",
        "    table = []\n",
        "\n",
        "    # Iterate through each class and calculate metrics\n",
        "    for class_index in range(num_classes):\n",
        "        precision = precision_score(all_targets[:, class_index], all_preds[:, class_index])\n",
        "        recall = recall_score(all_targets[:, class_index], all_preds[:, class_index])\n",
        "        f1 = f1_score(all_targets[:, class_index], all_preds[:, class_index])\n",
        "\n",
        "        f1_scores[class_names[class_index]] = {\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1\n",
        "        }\n",
        "        f1_sum += f1\n",
        "\n",
        "        # Append metrics for each class (using class names) to the table\n",
        "        table.append([class_names[class_index], precision, recall, f1])\n",
        "\n",
        "    # Calculate the average F1 score across all classes\n",
        "    average_f1 = f1_sum / num_classes\n",
        "\n",
        "    return accuracy.item(), f1_scores, average_f1, table , all_targets, all_preds # Return accuracy, F1 scores, and table\n",
        "\n",
        "# Example usage\n",
        "# Assuming you have a trained model, a data loader, a device, and a list of class names defined\n",
        "class_names = ['Actinic', 'Atopic', 'Benign', 'Candidiasis', 'Dermatitis', 'Dermatofibroma',\n",
        "               'Melanocytic', 'Melanoma', 'Ringworm', 'Squamous', 'Tinea', 'Vascular',\n",
        "               'Carcinoma', 'Cell', 'Keratosis', 'Lesion', 'Nevus']  # Replace with your actual class names\n",
        "accuracy, f1_scores, average_f1, table, all_targets, all_preds = evaluate_model(model, test_loader, device, class_names, threshold=0.1)\n",
        "\n",
        "# Print accuracy\n",
        "print(f\"\\nModel Accuracy: {accuracy:.4f}\\n\")\n",
        "\n",
        "# Display the table with class-wise metrics\n",
        "headers = [\"Class Name\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
        "print(tabulate(table, headers, floatfmt=\".4f\"))\n",
        "\n",
        "# Print average F1 score\n",
        "print(f\"\\nAverage F1 Score: {average_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbiBBrJBESJv",
        "outputId": "1538adaf-2849-418b-80d7-6a15aaa5d071"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all_targets.shape: torch.Size([454, 17])\n",
            "class_names length: 17\n",
            "\n",
            "Model Accuracy: 0.9671\n",
            "\n",
            "Class Name        Precision    Recall    F1 Score\n",
            "--------------  -----------  --------  ----------\n",
            "Actinic              0.7895    0.8824      0.8333\n",
            "Atopic               0.9773    0.9556      0.9663\n",
            "Benign               0.8281    0.9464      0.8833\n",
            "Candidiasis          1.0000    1.0000      1.0000\n",
            "Dermatitis           0.9773    0.9556      0.9663\n",
            "Dermatofibroma       0.9355    0.5370      0.6824\n",
            "Melanocytic          0.8250    0.8462      0.8354\n",
            "Melanoma             0.6944    0.5682      0.6250\n",
            "Ringworm             1.0000    1.0000      1.0000\n",
            "Squamous             0.8387    0.4815      0.6118\n",
            "Tinea                1.0000    1.0000      1.0000\n",
            "Vascular             1.0000    0.9804      0.9901\n",
            "Carcinoma            0.8333    0.4630      0.5952\n",
            "Cell                 0.8065    0.4630      0.5882\n",
            "Keratosis            0.9130    0.7850      0.8442\n",
            "Lesion               1.0000    0.9804      0.9901\n",
            "Nevus                0.8500    0.8718      0.8608\n",
            "\n",
            "Average F1 Score: 0.8396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Top K-Accuracy"
      ],
      "metadata": {
        "id": "K-KP7LM3b-K5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_accuracy_multilabel(model, test_loader, device, k=5):\n",
        "    \"\"\"\n",
        "    Calculate the Top-K accuracy for a multi-label classification model.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The trained model.\n",
        "        test_loader (torch.utils.data.DataLoader): Data loader for the evaluation dataset.\n",
        "        device (torch.device): The device to run the model on (CPU or GPU).\n",
        "        k (int): The number of top predictions to consider for Top-K accuracy.\n",
        "\n",
        "    Returns:\n",
        "        float: The Top-K accuracy (as a percentage).\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct_top_k = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Get the model predictions\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Get the top K predictions for each input (sorted by probability)\n",
        "            _, top_k_preds = torch.topk(outputs, k, dim=1)  # Get the top K predicted indices\n",
        "\n",
        "            # For multi-label, we need to check if any of the true labels (that are '1') are in the top K\n",
        "            for i in range(labels.size(0)):  # Iterate over each sample in the batch\n",
        "                true_labels = (labels[i] == 1).nonzero(as_tuple=False).squeeze().tolist()  # Get indices of true labels\n",
        "\n",
        "                # If true_labels is an int (single label), convert it to a list\n",
        "                if isinstance(true_labels, int):\n",
        "                    true_labels = [true_labels]\n",
        "\n",
        "                # If any of the true labels are in the top K predictions\n",
        "                if any(label in top_k_preds[i].tolist() for label in true_labels):\n",
        "                    correct_top_k += 1\n",
        "\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "    # Calculate Top-K accuracy\n",
        "    top_k_acc = correct_top_k / total_samples\n",
        "\n",
        "    return top_k_acc * 100  # Return as percentage\n"
      ],
      "metadata": {
        "id": "Sav_GMVAjoO_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Top-5 accuracy for multi-label classification\n",
        "top_k_acc_multilabel = top_k_accuracy_multilabel(model, test_loader, device, k=5)\n",
        "print(f\"Top-5 Accuracy (Multi-Label): {top_k_acc_multilabel:.2f}%\")\n",
        "\n",
        "# Calculate Top-3 accuracy for multi-label classification\n",
        "top_k_acc_multilabel_3 = top_k_accuracy_multilabel(model, test_loader, device, k=3)\n",
        "print(f\"Top-3 Accuracy (Multi-Label): {top_k_acc_multilabel_3:.2f}%\")\n",
        "\n",
        "# Calculate Top-3 accuracy for multi-label classification\n",
        "top_k_acc_multilabel_4 = top_k_accuracy_multilabel(model, test_loader, device, k=1)\n",
        "print(f\"Top-1 Accuracy (Multi-Label): {top_k_acc_multilabel_4:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Nqjq7m3HJhS",
        "outputId": "68b37000-5ceb-48f3-8096-27d8a8dc0d20"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-5 Accuracy (Multi-Label): 95.37%\n",
            "Top-3 Accuracy (Multi-Label): 92.29%\n",
            "Top-1 Accuracy (Multi-Label): 84.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Testing"
      ],
      "metadata": {
        "id": "FUMcOM9vcGhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Define the image preprocessing pipeline\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Adjust the size according to the model input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Use the same normalization used during training\n",
        "])\n",
        "\n",
        "# Load and preprocess the image\n",
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')  # Load the image and convert to RGB\n",
        "    image = preprocess(image)  # Apply the preprocessing pipeline\n",
        "    image = image.unsqueeze(0)  # Add batch dimension\n",
        "    return image\n",
        "\n",
        "# Example usage\n",
        "image_path = '/content/Extracted_data/test/dr_30_1692_jpg.rf.291429d58e0d185902e099e5a37ed838.jpg'\n",
        "image_tensor = preprocess_image(image_path)\n"
      ],
      "metadata": {
        "id": "5bm6c9Fv3hgy"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "9-ZhOiOtcJ4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the class for the image and return prediction values with class names\n",
        "def predict_image(model, image_tensor, device, class_names):\n",
        "    model.eval()\n",
        "    image_tensor = image_tensor.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)\n",
        "        preds = torch.sigmoid(outputs)  # Get probabilities (between 0 and 1)\n",
        "\n",
        "    # Convert tensor to numpy array for easier formatting\n",
        "    pred_numpy = preds.cpu().numpy()[0]  # Assuming batch size of 1, take first prediction\n",
        "\n",
        "    # Return the prediction probabilities with corresponding class names\n",
        "    return pred_numpy\n",
        "\n",
        "# Example usage\n",
        "image_tensor = preprocess_image(image_path)  # Assuming preprocess_image is defined elsewhere\n",
        "pred = predict_image(model, image_tensor, device, class_names)\n",
        "\n",
        "# Print class names with prediction values rounded to 4 decimal places\n",
        "for class_name, probability in zip(class_names, pred):\n",
        "    print(f\"{class_name}: {probability:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTmoIDIj89f4",
        "outputId": "05a84bfa-ca8e-43ae-ffd3-2ff32b6d9c0f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actinic: 0.0061\n",
            "Atopic: 0.0074\n",
            "Benign: 0.0105\n",
            "Candidiasis: 0.0170\n",
            "Dermatitis: 0.0049\n",
            "Dermatofibroma: 0.0057\n",
            "Melanocytic: 0.0237\n",
            "Melanoma: 0.1909\n",
            "Ringworm: 0.0135\n",
            "Squamous: 0.0416\n",
            "Tinea: 0.0158\n",
            "Vascular: 0.0060\n",
            "Carcinoma: 0.0356\n",
            "Cell: 0.0326\n",
            "Keratosis: 0.0089\n",
            "Lesion: 0.0093\n",
            "Nevus: 0.0168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display the Predictions"
      ],
      "metadata": {
        "id": "rYbXnQ-XcOKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class_names_or_highest(pred, class_names, threshold=0.1):\n",
        "    \"\"\"\n",
        "    Get the class names based on predicted probabilities and a specified threshold.\n",
        "    If no class meets the threshold, return the class name of the highest probability.\n",
        "\n",
        "    Args:\n",
        "        pred (torch.Tensor): Predicted probabilities from the model.\n",
        "        class_names (list): List of class names.\n",
        "        threshold (float): Threshold to determine the predicted classes.\n",
        "\n",
        "    Returns:\n",
        "        list: List of predicted class names or the class name with the highest probability.\n",
        "    \"\"\"\n",
        "    # Convert probabilities to binary predictions based on the threshold\n",
        "    predicted_classes = (pred > threshold).float()\n",
        "    class_indices = torch.nonzero(predicted_classes, as_tuple=True)[0]\n",
        "\n",
        "    if len(class_indices) > 0:\n",
        "        # If there are classes that exceed the threshold, return their names\n",
        "        return [class_names[idx] for idx in class_indices]\n",
        "    else:\n",
        "        # If no classes exceed the threshold, return the class name with the highest probability\n",
        "        highest_class_index = torch.argmax(pred).item()\n",
        "        return [class_names[highest_class_index]]  # Return as a list for consistency\n",
        "\n",
        "# Example usage\n",
        "pred = torch.tensor(pred)  # Ensure pred is a torch tensor if not already\n",
        "predicted_classes = get_class_names_or_highest(pred, class_names, threshold=0.1)\n",
        "\n",
        "print(f\"Predicted classes: {predicted_classes}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNQwmqFG9A2B",
        "outputId": "b1c177de-fdd7-46bd-b562-71bbfc824e69"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted classes: ['Melanoma']\n"
          ]
        }
      ]
    }
  ]
}